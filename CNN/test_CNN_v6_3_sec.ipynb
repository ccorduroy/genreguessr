{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df4ffec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms, datasets\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622f3091",
   "metadata": {},
   "source": [
    "# PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23eb133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the model\n",
    "n_pixels = 512*512\n",
    "n_classes = 10\n",
    "\n",
    "# Parameters for the training\n",
    "USE_CPU = False\n",
    "reg_val = 1e-4\n",
    "lr = 0.001 / 2\n",
    "batchsize = 32\n",
    "\n",
    "# For version control\n",
    "version_number = 6\n",
    "spectro_len = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e90ee69",
   "metadata": {},
   "source": [
    "# LOADING DATA \n",
    "\n",
    "## (WARNING: DO NOT RE-RUN THIS CODE AFTER TRAINING!!! - dataset indices will get overwritten!!!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f3991d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 512])\n",
      "0\n",
      "Train set size: 700, Validation set size: 150, Test set size: 150\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize(mean=[.5], std=[.5])  # Normalize for Grayscale\n",
    "])\n",
    "\n",
    "# --- 2. Load dataset ---\n",
    "dataset = datasets.ImageFolder(root=f'sliding_spectrograms_{spectro_len}_seconds', transform=transform)\n",
    "\n",
    "\n",
    "# Split into train, val, test (80/10/10)\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "trainset, valset, testset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "#### DO NOT RE-RUN THIS CODE!!!\n",
    "torch.save(trainset.indices, f'train_indices_v{version_number}.pt')\n",
    "torch.save(valset.indices, f'val_indices_v{version_number}.pt')\n",
    "torch.save(testset.indices, f'test_indices_v{version_number}.pt')\n",
    "\n",
    "image, label = trainset[0] \n",
    "print(image.shape) # torch.Size([1, 28, 28])\n",
    "print(label) \n",
    "input_image_shape = image.shape\n",
    "\n",
    "print(f'Train set size: {len(trainset)}, Validation set size: {len(valset)}, Test set size: {len(testset)}')\n",
    "\n",
    "class FullDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset        \n",
    "        self.data, self.labels = self._load_data()\n",
    "        \n",
    "    def _load_data(self):\n",
    "        data = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in range(len(self.dataset)):\n",
    "            x, y = self.dataset[i]\n",
    "            data.append(x)\n",
    "            labels.append(y)\n",
    "        \n",
    "        return torch.stack(data), torch.tensor(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "    \n",
    "trainset = FullDataset(trainset)\n",
    "valset = FullDataset(valset)\n",
    "\n",
    "# Shuffle the data at the start of each epoch (only useful for training set)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=batchsize, shuffle=True)\n",
    "train_eval_loader = DataLoader(trainset, batch_size=batchsize, shuffle=False)\n",
    "valloader = DataLoader(valset, batch_size=batchsize, shuffle=False)\n",
    "testloader = DataLoader(testset, batch_size=batchsize, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf0c31b",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b4bd1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 512, 512]             320\n",
      "              ReLU-2         [-1, 32, 512, 512]               0\n",
      "       BatchNorm2d-3         [-1, 32, 512, 512]              64\n",
      "            Conv2d-4         [-1, 32, 512, 512]           9,248\n",
      "              ReLU-5         [-1, 32, 512, 512]               0\n",
      "       BatchNorm2d-6         [-1, 32, 512, 512]              64\n",
      "         MaxPool2d-7         [-1, 32, 256, 256]               0\n",
      "         Dropout2d-8         [-1, 32, 256, 256]               0\n",
      "            Conv2d-9         [-1, 64, 256, 256]          18,496\n",
      "             ReLU-10         [-1, 64, 256, 256]               0\n",
      "      BatchNorm2d-11         [-1, 64, 256, 256]             128\n",
      "           Conv2d-12         [-1, 64, 256, 256]          36,928\n",
      "             ReLU-13         [-1, 64, 256, 256]               0\n",
      "      BatchNorm2d-14         [-1, 64, 256, 256]             128\n",
      "        MaxPool2d-15         [-1, 64, 128, 128]               0\n",
      "        Dropout2d-16         [-1, 64, 128, 128]               0\n",
      "           Conv2d-17        [-1, 128, 128, 128]          73,856\n",
      "             ReLU-18        [-1, 128, 128, 128]               0\n",
      "      BatchNorm2d-19        [-1, 128, 128, 128]             256\n",
      "           Conv2d-20        [-1, 128, 128, 128]         147,584\n",
      "             ReLU-21        [-1, 128, 128, 128]               0\n",
      "      BatchNorm2d-22        [-1, 128, 128, 128]             256\n",
      "        MaxPool2d-23          [-1, 128, 64, 64]               0\n",
      "        Dropout2d-24          [-1, 128, 64, 64]               0\n",
      "           Conv2d-25          [-1, 256, 64, 64]         295,168\n",
      "             ReLU-26          [-1, 256, 64, 64]               0\n",
      "      BatchNorm2d-27          [-1, 256, 64, 64]             512\n",
      "           Conv2d-28          [-1, 256, 64, 64]         590,080\n",
      "             ReLU-29          [-1, 256, 64, 64]               0\n",
      "      BatchNorm2d-30          [-1, 256, 64, 64]             512\n",
      "        MaxPool2d-31          [-1, 256, 32, 32]               0\n",
      "        Dropout2d-32          [-1, 256, 32, 32]               0\n",
      "           Conv2d-33          [-1, 512, 32, 32]       1,180,160\n",
      "             ReLU-34          [-1, 512, 32, 32]               0\n",
      "      BatchNorm2d-35          [-1, 512, 32, 32]           1,024\n",
      "           Conv2d-36          [-1, 512, 32, 32]       2,359,808\n",
      "             ReLU-37          [-1, 512, 32, 32]               0\n",
      "      BatchNorm2d-38          [-1, 512, 32, 32]           1,024\n",
      "        MaxPool2d-39          [-1, 512, 16, 16]               0\n",
      "        Dropout2d-40          [-1, 512, 16, 16]               0\n",
      "           Linear-41                  [-1, 512]      67,109,376\n",
      "             ReLU-42                  [-1, 512]               0\n",
      "      BatchNorm1d-43                  [-1, 512]           1,024\n",
      "        Dropout1d-44                  [-1, 512]               0\n",
      "           Linear-45                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 71,831,146\n",
      "Trainable params: 71,831,146\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.00\n",
      "Forward/backward pass size (MB): 806.02\n",
      "Params size (MB): 274.01\n",
      "Estimated Total Size (MB): 1081.03\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "# for an alternative approach, see: mini_vgg_like_torch_1.py\n",
    "def vgg_like_block(in_channels, num_filters, ksize=3, drate=0.25, pad='same'):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, num_filters, kernel_size=ksize, padding=pad),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(num_filters),\n",
    "        nn.Conv2d(num_filters, num_filters, kernel_size=ksize, padding=pad),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(num_filters),\n",
    "        nn.MaxPool2d(kernel_size=2),\n",
    "        nn.Dropout2d(p=drate)\n",
    "    )\n",
    "\n",
    "def classifier_mlp(n_in, n_hidden, n_classes, drate=0.25):\n",
    "    return nn.Sequential(\n",
    "        # nn.Flatten(),\n",
    "        nn.Linear(n_in, n_hidden),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(n_hidden),\n",
    "        nn.Dropout1d(p=drate),\n",
    "        nn.Linear(n_hidden, n_classes)\n",
    "    )\n",
    "\n",
    "class MiniVgg(nn.Module):\n",
    "    def __init__(self, b1_filters=32, b2_filters=64, b3_filters=128, b4_filters=256, b5_filters=512, H=512, W=512, fc_nodes=512, n_classes=10):\n",
    "        super().__init__()\n",
    "        self.block1 = vgg_like_block(1, b1_filters)\n",
    "        self.block2 = vgg_like_block(b1_filters, b2_filters)\n",
    "        self.block3 = vgg_like_block(b2_filters, b3_filters)\n",
    "        self.block4 = vgg_like_block(b3_filters, b4_filters)\n",
    "        self.block5 = vgg_like_block(b4_filters, b5_filters)\n",
    "        assert H % 4 == 0, f'the image height and width must be a multiple of 4: you passed H = {H}'\n",
    "        mlp_in_size = (H * W // 1024) * b5_filters  # the H and W are both reduced by 32 with 5 max-pool layers.\n",
    "        self.classifier = classifier_mlp(mlp_in_size, fc_nodes, n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        print(batch_size)\n",
    "        y = self.block1(x)\n",
    "        y = self.block2(y)\n",
    "        y = self.block3(y)\n",
    "        y = self.block4(y)\n",
    "        y = self.block5(y)\n",
    "        y = y.view(batch_size, -1)\n",
    "        # y_rnn = y\n",
    "        y = self.classifier(y)\n",
    "        # print(\"GOT HERE\")\n",
    "        return y\n",
    "\n",
    "model = MiniVgg()\n",
    "# print(model)\n",
    "summary(model, input_image_shape)  # call summary before moving the model to a device...\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # includes softmax (for numerical stability)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=reg_val)  # default learning rate is 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae72c78d",
   "metadata": {},
   "source": [
    "# TRAIN/VALIDATE FUNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf09cb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# set the device to use and move model to device\n",
    "\n",
    "if USE_CPU:\n",
    "    device = torch.device(\"cpu\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "elif torch.torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\") # MPS acceleration is available on MacOS 12.3+\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f'Using device: {device}')\n",
    "model.to(device) # Move model to device\n",
    "\n",
    "# Define function to call for each training epoch (one complete pass over the training set)\n",
    "def train(model, trainloader, criterion, optimizer, device):\n",
    "    model.train() # set model to training mode\n",
    "    running_loss = 0; running_acc = 0\n",
    "    with tqdm(total=len(trainloader), desc=f\"Train\", unit=\"batch\") as pbar:\n",
    "        for n_batch, (images, labels) in enumerate(trainloader): # Iterate over batches\n",
    "            images, labels = images.to(device), labels.to(device) # Move batch to device\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images) # Forward pass\n",
    "            loss = criterion(output, labels) # Compute loss\n",
    "            loss.backward() # Backward pass\n",
    "            optimizer.step() # Update weights\n",
    "            running_loss += loss.item()\n",
    "            running_acc += (output.argmax(1) == labels).float().mean().item()\n",
    "            # pbar.set_postfix({'loss': loss.item(), 'acc': 100. * running_acc / (n_batch+1)})\n",
    "            pbar.set_postfix({'loss': running_loss / (n_batch+1), 'acc': 100. * running_acc / (n_batch+1)})\n",
    "            pbar.update() # Update progress bar\n",
    "    return running_loss / len(trainloader), running_acc / len(trainloader) # return loss and accuracy for this epoch\n",
    "\n",
    "# Define function to call for each validation epoch (one complete pass over the validation set)\n",
    "def validate(model, valloader, criterion, device, tag='Val'):\n",
    "    model.eval() # set model to evaluation mode (e.g. turn off dropout, batchnorm, etc.)\n",
    "    running_loss = 0; running_acc = 0\n",
    "    with torch.no_grad(): # no need to compute gradients for validation\n",
    "        with tqdm(total=len(valloader), desc=tag, unit=\"batch\") as pbar:\n",
    "            for n_batch, (images, labels) in enumerate(valloader): # Iterate over batches\n",
    "                images, labels = images.to(device), labels.to(device) # Move batch to device\n",
    "                output = model(images) # Forward pass\n",
    "                loss = criterion(output, labels) # Compute loss\n",
    "                running_loss += loss.item() \n",
    "                running_acc += (output.argmax(1) == labels).float().mean().item()\n",
    "                pbar.set_postfix({'loss': running_loss / (n_batch+1), 'acc': 100. * running_acc / (n_batch+1)})\n",
    "                pbar.update() # Update progress bar\n",
    "    return running_loss / len(valloader), running_acc / len(valloader)  # return loss and accuracy for this epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45da66c",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9430ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/22 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   5%|▍         | 1/22 [00:15<05:16, 15.09s/batch, loss=2.42, acc=6.25]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   9%|▉         | 2/22 [00:30<05:01, 15.09s/batch, loss=2.95, acc=18.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  14%|█▎        | 3/22 [00:45<04:46, 15.07s/batch, loss=2.87, acc=26]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  14%|█▎        | 3/22 [01:00<06:22, 20.14s/batch, loss=2.87, acc=26]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReducing learning rate from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m---> 13\u001b[0m train_loss, train_acc  \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m     14\u001b[0m train_loss, train_acc  \u001b[38;5;241m=\u001b[39m validate(model, train_eval_loader, criterion, device, tag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Eval\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# Evaluate on Train data\u001b[39;00m\n\u001b[0;32m     15\u001b[0m val_loss, val_acc \u001b[38;5;241m=\u001b[39m validate(model, valloader, criterion, device) \u001b[38;5;66;03m# Validate\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[12], line 25\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, trainloader, criterion, optimizer, device)\u001b[0m\n\u001b[0;32m     23\u001b[0m output \u001b[38;5;241m=\u001b[39m model(images) \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, labels) \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[0;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m# Update weights\u001b[39;00m\n\u001b[0;32m     27\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\leduo\\Desktop\\ee460\\.conda\\lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\leduo\\Desktop\\ee460\\.conda\\lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\leduo\\Desktop\\ee460\\.conda\\lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run training and validation loop\n",
    "# Save the best model based on validation accuracy\n",
    "n_epochs = 20\n",
    "best_acc = -1\n",
    "train_loss_history = []; train_acc_history = []\n",
    "val_loss_history = []; val_acc_history = []\n",
    "for epoch in range(n_epochs): # Iterate over epochs\n",
    "    print(f\"\\nEpoch {epoch+1} of {n_epochs}\")\n",
    "    if epoch == n_epochs // 2:\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "        print(f'Reducing learning rate from {lr} to {lr/4}')\n",
    "        optimizer.param_groups[0]['lr'] /= 4\n",
    "    train_loss, train_acc  = train(model, trainloader, criterion, optimizer, device) # Train\n",
    "    train_loss, train_acc  = validate(model, train_eval_loader, criterion, device, tag='Train Eval') # Evaluate on Train data\n",
    "    val_loss, val_acc = validate(model, valloader, criterion, device) # Validate\n",
    "    train_loss_history.append(train_loss); train_acc_history.append(train_acc)\n",
    "    val_loss_history.append(val_loss); val_acc_history.append(val_acc)\n",
    "    if val_acc > best_acc: # Save best model\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), f\"best_model_v{version_number}.pt\") # saving model parameters (\"state_dict\") saves memory and is faster than saving the entire model\n",
    "\n",
    "epochs = torch.arange(n_epochs)\n",
    "\n",
    "# plot training and validation loss\n",
    "plt.figure()\n",
    "plt.plot(epochs, train_loss_history, label='train_loss')\n",
    "plt.plot(epochs, val_loss_history, label='val_loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Multiclass Cross Entropy Loss')\n",
    "plt.title(f'Loss with miniVGG model')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot training and validation accuracy\n",
    "plt.figure()\n",
    "plt.plot(epochs, train_acc_history, label='train_acc')\n",
    "plt.plot(epochs, val_acc_history, label='val_acc')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(f'Accuracy with miniVGG model; Regularizer: {reg_val : 3.2g}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "model.eval() # set model to evaluation mode "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d6b7ba",
   "metadata": {},
   "source": [
    "# EVALUATION & ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af79a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model and evaluate on test set\n",
    "model.load_state_dict(torch.load(f\"best_model_v{version_number}.pt\"))\n",
    "test_loss, test_acc = validate(model, testloader, criterion, device)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a333e7d0",
   "metadata": {},
   "source": [
    "# RECREATE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c46320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreating Test Set \n",
    "\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Converts [0-255] RGBA to [0.0-1.0], shape [3, H, W]\n",
    "    transforms.Normalize(mean=[.5,.5,.5], std=[.5,.5,.5])  # Normalize for RGB\n",
    "])\n",
    "\n",
    "# Rebuild the original dataset\n",
    "dataset = datasets.ImageFolder(root=f'sliding_spectrograms_{spectro_len}_seconds', transform=transform)\n",
    "\n",
    "# Load indices\n",
    "train_indices = torch.load(f'train_indices_v{version_number}.pt')\n",
    "val_indices = torch.load(f'val_indices_v{version_number}.pt')\n",
    "test_indices = torch.load(f'test_indices_v{version_number}.pt')\n",
    "\n",
    "# Recreate test subset\n",
    "trainset = Subset(dataset, train_indices)\n",
    "valset = Subset(dataset, val_indices)\n",
    "testset = Subset(dataset, test_indices)\n",
    "\n",
    "batchsize = 32\n",
    "\n",
    "# Create DataLoader\n",
    "# trainloader = DataLoader(trainset, batch_size=batchsize, shuffle=True)\n",
    "# train_eval_loader = DataLoader(trainset, batch_size=batchsize, shuffle=False)\n",
    "# valloader = DataLoader(valset, batch_size=batchsize, shuffle=False)\n",
    "testloader = DataLoader(testset, batch_size=batchsize, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b56dbc",
   "metadata": {},
   "source": [
    "CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a96039",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    " \n",
    "# model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "genre_list = [\"blues\", \"classical\", \"country\", \"disco\", \"hiphop\", \"jazz\", \"metal\", \"pop\", \"reggae\", \"rock\"]\n",
    "\n",
    "for inputs, labels in testloader:  # Replace `testloader` with your DataLoader\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move to the appropriate device (GPU or CPU)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Get the predictions\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        # Store all predictions and labels\n",
    "        all_preds.extend(preds.cpu().numpy())  # Convert to numpy and add to list\n",
    "        all_labels.extend(labels.cpu().numpy())  # Convert to numpy and add to list\n",
    "\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "class_labels = [genre_list[label] for label in all_labels]\n",
    "\n",
    "# Plot the confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=genre_list, yticklabels=genre_list)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

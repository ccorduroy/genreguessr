{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4ffec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms, datasets\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Parameters for the model\n",
    "n_pixels = 28 * 28\n",
    "n_classes = 10\n",
    "\n",
    "# Parameters for the training\n",
    "USE_CPU = False\n",
    "reg_val = 1e-4\n",
    "lr = 0.001 / 2\n",
    "batchsize = 32\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Converts [0-255] RGBA to [0.0-1.0], shape [3, H, W]\n",
    "    transforms.Normalize(mean=[.5,.5,.5], std=[.5,.5,.5])  # Normalize for RGB\n",
    "])\n",
    "\n",
    "# --- 2. Load dataset ---\n",
    "dataset = datasets.ImageFolder(root='sliding_spectrograms_10_seconds', transform=transform)\n",
    "\n",
    "\n",
    "# Split into train, val, test (80/10/10)\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "trainset, valset, testset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "\n",
    "torch.save(trainset.indices, 'train_indices.pt')\n",
    "torch.save(valset.indices, 'val_indices.pt')\n",
    "torch.save(testset.indices, 'test_indices.pt')\n",
    "\n",
    "image, label = trainset[0] \n",
    "print(image.shape) # torch.Size([1, 28, 28])\n",
    "print(label) \n",
    "input_image_shape = image.shape\n",
    "\n",
    "print(f'Train set size: {len(trainset)}, Validation set size: {len(valset)}, Test set size: {len(testset)}')\n",
    "\n",
    "class FullDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset        \n",
    "        self.data, self.labels = self._load_data()\n",
    "        \n",
    "    def _load_data(self):\n",
    "        data = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in range(len(self.dataset)):\n",
    "            x, y = self.dataset[i]\n",
    "            data.append(x)\n",
    "            labels.append(y)\n",
    "        \n",
    "        return torch.stack(data), torch.tensor(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "    \n",
    "trainset = FullDataset(trainset)\n",
    "valset = FullDataset(valset)\n",
    "\n",
    "# Shuffle the data at the start of each epoch (only useful for training set)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=batchsize, shuffle=True)\n",
    "train_eval_loader = DataLoader(trainset, batch_size=batchsize, shuffle=False)\n",
    "valloader = DataLoader(valset, batch_size=batchsize, shuffle=False)\n",
    "testloader = DataLoader(testset, batch_size=batchsize, shuffle=False)\n",
    "\n",
    "# Define the model\n",
    "# for an alternative approach, see: mini_vgg_like_torch_1.py\n",
    "def vgg_like_block(in_channels, num_filters, ksize=3, drate=0.25, pad='same'):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, num_filters, kernel_size=ksize, padding=pad),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(num_filters),\n",
    "        nn.Conv2d(num_filters, num_filters, kernel_size=ksize, padding=pad),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(num_filters),\n",
    "        nn.MaxPool2d(kernel_size=2),\n",
    "        nn.Dropout2d(p=drate)\n",
    "    )\n",
    "\n",
    "def classifier_mlp(n_in, n_hidden, n_classes, drate=0.25):\n",
    "    return nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(n_in, n_hidden),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(n_hidden),\n",
    "        nn.Dropout1d(p=drate),\n",
    "        nn.Linear(n_hidden, n_classes)\n",
    "    )\n",
    "\n",
    "class MiniVgg(nn.Module):\n",
    "    def __init__(self, b1_filters=32, b2_filters=64, H=480, W=640, fc_nodes=512, n_classes=10):\n",
    "        super().__init__()\n",
    "        self.block1 = vgg_like_block(3, b1_filters)\n",
    "        self.block2 = vgg_like_block(b1_filters, b2_filters)\n",
    "        assert H % 4 == 0, f'the image height and width must be a multiple of 4: you passed H = {H}'\n",
    "        mlp_in_size = (H * W // 16) * b2_filters  # the H and W are both reduced by 4 with 2 max-pool layers.\n",
    "        self.classifier = classifier_mlp(mlp_in_size, fc_nodes, n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        y = self.block1(x)\n",
    "        y = self.block2(y)\n",
    "        y = y.view(batch_size, -1)\n",
    "        y = self.classifier(y)\n",
    "        return y\n",
    "\n",
    "model = MiniVgg()\n",
    "print(model)\n",
    "summary(model, input_image_shape)  # call summary before moving the model to a device...\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # includes softmax (for numerical stability)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=reg_val)  # default learning rate is 0.001\n",
    "\n",
    "# set the device to use and move model to device\n",
    "\n",
    "if USE_CPU:\n",
    "    device = torch.device(\"cpu\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "elif torch.torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\") # MPS acceleration is available on MacOS 12.3+\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f'Using device: {device}')\n",
    "model.to(device) # Move model to device\n",
    "\n",
    "\n",
    "# Define function to call for each training epoch (one complete pass over the training set)\n",
    "def train(model, trainloader, criterion, optimizer, device):\n",
    "    model.train() # set model to training mode\n",
    "    running_loss = 0; running_acc = 0\n",
    "    with tqdm(total=len(trainloader), desc=f\"Train\", unit=\"batch\") as pbar:\n",
    "        for n_batch, (images, labels) in enumerate(trainloader): # Iterate over batches\n",
    "            images, labels = images.to(device), labels.to(device) # Move batch to device\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images) # Forward pass\n",
    "            loss = criterion(output, labels) # Compute loss\n",
    "            loss.backward() # Backward pass\n",
    "            optimizer.step() # Update weights\n",
    "            running_loss += loss.item()\n",
    "            running_acc += (output.argmax(1) == labels).float().mean().item()\n",
    "            # pbar.set_postfix({'loss': loss.item(), 'acc': 100. * running_acc / (n_batch+1)})\n",
    "            pbar.set_postfix({'loss': running_loss / (n_batch+1), 'acc': 100. * running_acc / (n_batch+1)})\n",
    "            pbar.update() # Update progress bar\n",
    "    return running_loss / len(trainloader), running_acc / len(trainloader) # return loss and accuracy for this epoch\n",
    "\n",
    "# Define function to call for each validation epoch (one complete pass over the validation set)\n",
    "def validate(model, valloader, criterion, device, tag='Val'):\n",
    "    model.eval() # set model to evaluation mode (e.g. turn off dropout, batchnorm, etc.)\n",
    "    running_loss = 0; running_acc = 0\n",
    "    with torch.no_grad(): # no need to compute gradients for validation\n",
    "        with tqdm(total=len(valloader), desc=tag, unit=\"batch\") as pbar:\n",
    "            for n_batch, (images, labels) in enumerate(valloader): # Iterate over batches\n",
    "                images, labels = images.to(device), labels.to(device) # Move batch to device\n",
    "                output = model(images) # Forward pass\n",
    "                loss = criterion(output, labels) # Compute loss\n",
    "                running_loss += loss.item() \n",
    "                running_acc += (output.argmax(1) == labels).float().mean().item()\n",
    "                pbar.set_postfix({'loss': running_loss / (n_batch+1), 'acc': 100. * running_acc / (n_batch+1)})\n",
    "                pbar.update() # Update progress bar\n",
    "    return running_loss / len(valloader), running_acc / len(valloader)  # return loss and accuracy for this epoch\n",
    "\n",
    "# Run training and validation loop\n",
    "# Save the best model based on validation accuracy\n",
    "n_epochs = 20\n",
    "best_acc = -1\n",
    "train_loss_history = []; train_acc_history = []\n",
    "val_loss_history = []; val_acc_history = []\n",
    "for epoch in range(n_epochs): # Iterate over epochs\n",
    "    print(f\"\\nEpoch {epoch+1} of {n_epochs}\")\n",
    "    if epoch == n_epochs // 2:\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "        print(f'Reducing learning rate from {lr} to {lr/4}')\n",
    "        optimizer.param_groups[0]['lr'] /= 4\n",
    "    train_loss, train_acc  = train(model, trainloader, criterion, optimizer, device) # Train\n",
    "    train_loss, train_acc  = validate(model, train_eval_loader, criterion, device, tag='Train Eval') # Evaluate on Train data\n",
    "    val_loss, val_acc = validate(model, valloader, criterion, device) # Validate\n",
    "    train_loss_history.append(train_loss); train_acc_history.append(train_acc)\n",
    "    val_loss_history.append(val_loss); val_acc_history.append(val_acc)\n",
    "    if val_acc > best_acc: # Save best model\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_model_v4.pt\") # saving model parameters (\"state_dict\") saves memory and is faster than saving the entire model\n",
    "\n",
    "epochs = torch.arange(n_epochs)\n",
    "\n",
    "# plot training and validation loss\n",
    "plt.figure()\n",
    "plt.plot(epochs, train_loss_history, label='train_loss')\n",
    "plt.plot(epochs, val_loss_history, label='val_loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Multiclass Cross Entropy Loss')\n",
    "plt.title(f'Loss with miniVGG model')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot training and validation accuracy\n",
    "plt.figure()\n",
    "plt.plot(epochs, train_acc_history, label='train_acc')\n",
    "plt.plot(epochs, val_acc_history, label='val_acc')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(f'Accuracy with miniVGG model; Regularizer: {reg_val : 3.2g}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Load the best model and evaluate on test set\n",
    "model.load_state_dict(torch.load(\"best_model_v4.pt\"))\n",
    "test_loss, test_acc = validate(model, testloader, criterion, device)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "model.eval() # set model to evaluation mode \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b56dbc",
   "metadata": {},
   "source": [
    "CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a96039",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    " \n",
    "# model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "genre_list = [\"blues\", \"classical\", \"country\", \"disco\", \"hiphop\", \"jazz\", \"metal\", \"pop\", \"reggae\", \"rock\"]\n",
    "\n",
    "for inputs, labels in testloader:  # Replace `testloader` with your DataLoader\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move to the appropriate device (GPU or CPU)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Get the predictions\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        # Store all predictions and labels\n",
    "        all_preds.extend(preds.cpu().numpy())  # Convert to numpy and add to list\n",
    "        all_labels.extend(labels.cpu().numpy())  # Convert to numpy and add to list\n",
    "\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "class_labels = [genre_list[label] for label in all_labels]\n",
    "\n",
    "# Plot the confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=genre_list, yticklabels=genre_list)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c569005",
   "metadata": {},
   "source": [
    "RECREATE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4164711",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Subset\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Rebuild the original dataset\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241m.\u001b[39mImageFolder(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msliding_spectrograms_10_seconds\u001b[39m\u001b[38;5;124m'\u001b[39m, transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Load indices\u001b[39;00m\n\u001b[0;32m      9\u001b[0m train_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_indices.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datasets' is not defined"
     ]
    }
   ],
   "source": [
    "# Recreating Test Set \n",
    "\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# Rebuild the original dataset\n",
    "dataset = datasets.ImageFolder(root='sliding_spectrograms_10_seconds', transform=transform)\n",
    "\n",
    "# Load indices\n",
    "train_indices = torch.load('train_indices.pt')\n",
    "val_indices = torch.load('val_indices.pt')\n",
    "test_indices = torch.load('test_indices.pt')\n",
    "\n",
    "# Recreate test subset\n",
    "trainset = Subset(dataset, train_indices)\n",
    "valset = Subset(dataset, val_indices)\n",
    "testset = Subset(dataset, test_indices)\n",
    "\n",
    "batchsize = 32\n",
    "\n",
    "# Create DataLoader\n",
    "# trainloader = DataLoader(trainset, batch_size=batchsize, shuffle=True)\n",
    "# train_eval_loader = DataLoader(trainset, batch_size=batchsize, shuffle=False)\n",
    "# valloader = DataLoader(valset, batch_size=batchsize, shuffle=False)\n",
    "testloader = DataLoader(testset, batch_size=batchsize, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN + RNN Genre Classification using Pretrained MiniVGG\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Dataset Preparation ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5, .5, .5], std=[.5, .5, .5])\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root='sliding_spectrograms_10_seconds', transform=transform)\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "trainset, valset, testset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "valloader = DataLoader(valset, batch_size=32, shuffle=False)\n",
    "testloader = DataLoader(testset, batch_size=32, shuffle=False)\n",
    "\n",
    "# --- MiniVGG Feature Extractor (Pretrained) ---\n",
    "class MiniVgg(nn.Module):\n",
    "    def __init__(self, b1_filters=32, b2_filters=64):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, b1_filters, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(b1_filters),\n",
    "            nn.Conv2d(b1_filters, b1_filters, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(b1_filters),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout2d(0.25)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(b1_filters, b2_filters, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(b2_filters),\n",
    "            nn.Conv2d(b2_filters, b2_filters, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(b2_filters),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout2d(0.25)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        return x  # [B, C, H, W]\n",
    "\n",
    "# --- CNN + RNN Combined Model ---\n",
    "class CNNRNNClassifier(nn.Module):\n",
    "    def __init__(self, cnn_model, cnn_out_channels=64, rnn_hidden_dim=64, num_layers=2, num_classes=10, bidirectional=True):\n",
    "        super(CNNRNNClassifier, self).__init__()\n",
    "        self.cnn = cnn_model\n",
    "        for param in self.cnn.parameters():\n",
    "            param.requires_grad = False  # Freeze CNN\n",
    "\n",
    "        self.rnn_input_dim = cnn_out_channels * (128 // 4)  # H becomes H//4 from two pooling layers\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=self.rnn_input_dim,\n",
    "            hidden_size=rnn_hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(rnn_hidden_dim * (2 if bidirectional else 1), num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            cnn_out = self.cnn(x)  # [B, C, H, W]\n",
    "\n",
    "        B, C, H, W = cnn_out.shape\n",
    "        rnn_in = cnn_out.view(B, C * H, W).permute(0, 2, 1)  # [B, T=W, F=C*H]\n",
    "        rnn_out, _ = self.rnn(rnn_in)\n",
    "        final_out = self.dropout(rnn_out[:, -1, :])\n",
    "        return self.fc(final_out)\n",
    "\n",
    "# --- Training and Evaluation Loops ---\n",
    "def train(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    loss_sum = 0; correct = 0\n",
    "    for x, y in tqdm(loader, desc='Train'):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum += loss.item()\n",
    "        correct += (logits.argmax(1) == y).sum().item()\n",
    "    return loss_sum / len(loader), correct / len(loader.dataset)\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    loss_sum = 0; correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(loader, desc='Eval'):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            loss_sum += loss.item()\n",
    "            correct += (logits.argmax(1) == y).sum().item()\n",
    "    return loss_sum / len(loader), correct / len(loader.dataset)\n",
    "\n",
    "# --- Main Execution ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "cnn_model = MiniVgg()\n",
    "cnn_model.load_state_dict(torch.load(\"best_model_v4.pt\"))  # Load your pretrained CNN\n",
    "model = CNNRNNClassifier(cnn_model).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{n_epochs}\")\n",
    "    tr_loss, tr_acc = train(model, trainloader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = evaluate(model, valloader, criterion, device)\n",
    "    train_losses.append(tr_loss); val_losses.append(val_loss)\n",
    "    train_accuracies.append(tr_acc); val_accuracies.append(val_acc)\n",
    "    print(f\"Train Loss: {tr_loss:.4f}, Acc: {tr_acc:.4f} | Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
    "\n",
    "# --- Plotting ---\n",
    "epochs = list(range(1, n_epochs+1))\n",
    "plt.figure()\n",
    "plt.plot(epochs, train_losses, label='Train Loss')\n",
    "plt.plot(epochs, val_losses, label='Val Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Loss')\n",
    "plt.legend(); plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, train_accuracies, label='Train Acc')\n",
    "plt.plot(epochs, val_accuracies, label='Val Acc')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Accuracy')\n",
    "plt.legend(); plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# --- Final Test Accuracy ---\n",
    "test_loss, test_acc = evaluate(model, testloader, criterion, device)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ee460",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
